{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Homepage","text":"<p>For pipeline code visit HARMLINC GitHub Repo.</p>"},{"location":"#overview","title":"Overview","text":"<ul> <li>HAMRLINC is a multipurpose toolbox that expedites the analysis pipeline of two algorithms: HAMR and Evolinc. The former was developed by Paul Ryvkin et al, and the latter by Andrew D.L. Nelson et al. HAMRLINC aims to make the original methods more accessible by automating the tedious pre-processing steps, and expand on their functionalities with its built-in post-processing steps, allowing users to perform RNA modification prediction with intuitive output formats, lincRNA identification and transcripts abundance quantifiction using the same RNA-Seq input data.</li> <li>HAMRLINC is high-throughput and performs RNA-modification analysis, long intergenic non-coding RNAs(lincRNA) annotation and transcripts abundance quantification at a bioproject scale. HAMRLINC performs constitutive trimming of acquired reads using Trim-Galore, and makes use of STAR (Tophat option available) as the default aligning tool; mapped reads are pre-processed using selected methods from GATK and samtools.</li> <li>HAMRLINC is optimized for partial parallel processing, and modularization. Specifying a larger thread count where hardware permits will greatly increase the efficiency of a run. If only partial functionality is needed (e.g. Only analyzing modified ribonucleotides), users can use flags to activate needed function modules as they desire. See below for more details .</li> </ul>"},{"location":"#harmlinc-workflow","title":"HARMLINC Workflow","text":"HAMRLINC workflow: Overview of the data flow of HAMRLINC, from input data, which could be raw FASTQ files or list of SRA-IDs to quality control, trimming, mapping, pre-processing and downstream analysis. Pre-processing steps are in yellow, main steps are in grey and, check-points are in peach."},{"location":"Tutorial/","title":"Tutorial","text":""},{"location":"Tutorial/#some-notes-on-inputs","title":"Some Notes on Inputs","text":"<p>Please carefully read this section as inadequate inputs can impact the proper functioning of the software. If you ever wondered \"why did they do this\" when running the demo, you should be able to find your answer here. </p>"},{"location":"Tutorial/#-c","title":"-c","text":"<p>This .csv is the most crucial. It's a guide for HAMRLINC to locate your fastq files and present your samples in later visualizations. There are 2 columns. Left column contains the keys and right column contains the values. </p>"},{"location":"Tutorial/#keys","title":"Keys","text":"<p>Either SRR accession codes, or the file basename of the fastq input directory. If you decide to use SRR accession codes, the entire column must be SRR accession codes, visa versa. If you use SRR accession codes, each code must correspond to an existing entry in the Sequence Read Archive database. If you input your own fastq files, the file basenames should NOT include the file suffix like .fq or .fastq.gz in your csv file. See paired end example below.</p>"},{"location":"Tutorial/#values","title":"Values","text":"<p>Succinct names for each fastq file in the context of the experiment. The naming must follow the form: SAMPLE_SEQTECH_REP. Note \"_\" is the delimiter and is crucial for the program. TREATMENT includes information on variant, genotype, and treatment. SEQTECH is the sequencing method used. REP is the biological replicate number. Below are some examples.</p>"},{"location":"Tutorial/#file-naming-conventions-examples","title":"File Naming Conventions Examples","text":"File name in csv Actual sample LemontHeat_mRNA_rep2 a fastq file generated from mRNA-sequencing replicate 2 of a heat-treated Lemont variant O. sativa individual dxo1Salt_GMUCT_rep1 a fastq file generated from GMUCT sequencing replicate 1 of a salt-treated A. thaliana individual with the gene AtDXO1 knocked out <p>The demo csv files are great examples for what the actual file should look like. </p>"},{"location":"Tutorial/#paired-end","title":"Paired End","text":"<p>In the case of paired end sequencing, ignore the _1 and _2 in your key, and create only 1 row for each paired end sample. For example, if one of your soybean samples are paired end sequenced as /path/to/2024-1-2-soy-illumina3000-XYZ_1.fq and /path/to/2024-1-2-soy-illumina3000-XYZ_2.fq, in your csv, the row for this sample should look something like </p>"},{"location":"Tutorial/#example","title":"Example","text":"Key Value 2024-1-2-soy-illumina3000-XYZ soyWT_mRNA_rep1"},{"location":"Tutorial/#-d","title":"-d","text":"<p>The input folder should contain only your fastq files, and nothing else. 4 types of suffixes are supported: .fq / .fastq / .fq.gz / .fastq.gz</p>"},{"location":"Tutorial/#tophat2-mode","title":"TopHat2 mode","text":"<p>We recommend using STAR aligner for its speed and simplicity. However if you'd like to use TopHat2, you can use -a to activate it. In such case, you can also input a genome index folder with the flag -x. If none is inputted, the program will use bowtie2 to create one. </p>"},{"location":"Tutorial/#-k-p-u","title":"-k, -p, -u","text":"<p>The analysis steps are condensed into three modules, and each of these options can activate one of them. If none of these three flags are included, HAMRLINC will not perform any analysis. </p>"},{"location":"Tutorial/#required-dependencies","title":"Required Dependencies","text":"<ul> <li>Linux-based computer, server, or cluster</li> <li>Docker</li> <li>Minimum memory of 32 GB and minimum disk space of 120 GB</li> </ul>"},{"location":"Tutorial/#demo-data-source","title":"Demo Data source","text":"<p>For this tutorial, we'll be using the RNA-Seq data generated by Yu et al 2021. In this work, they report that Messenger RNA 5\u2032 NAD+ capping is a dynamic regulatory epitranscriptome mark that is required for proper response to abscisic acid in Arabidopsis. A graphic abstract is shown below:</p> <p> </p> Yu et al 2021 article graphic abstract"},{"location":"Tutorial/#pulling-hamrlinc-docker-image","title":"Pulling HAMRLINC Docker Image","text":"<p>To run HAMRLINC, you need to first pull the docker image for the pipeline to your computer. If you are not familiar with container technology and would like to learn the basics, please check out CyVerse Container &amp; Cloud Native Camp Documentation. It is open source and free. Dig in!</p> <p>Pull HAMRLINC docker image. This should take a few minutes depending on your internet speed. <pre><code>docker pull chosenobih/hamrlinc:v0.3\n</code></pre> After building the conatiner, run the code below to be sure that you now have the image on your computer <pre><code>docker image ls\n</code></pre> Your ouput should be similar to the image below: </p> <p>clone HAMRLINC repo <pre><code>git clone https://github.com/chosenobih/HAMRLINC.git\ncd HAMRLINC\n</code></pre> download the genome file for Arabidopsis thaliana from ENSEMBL <pre><code>wget https://ftp.ensemblgenomes.ebi.ac.uk/pub/plants/release-57/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz\ngunzip Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz\n</code></pre> download the annotation file for Arabidopsis thaliana from ENSEMBL <pre><code>wget https://ftp.ensemblgenomes.ebi.ac.uk/pub/plants/release-57/gff3/arabidopsis_thaliana/Arabidopsis_thaliana.TAIR10.57.gff3.gz\ngunzip Arabidopsis_thaliana.TAIR10.57.gff3.gz\n</code></pre> run HAMRLINC in SE mode with SRA IDs. Only RNA modification annotation analysis arm is activated <pre><code>docker run --rm -v $(pwd):/working-dir -w /working-dir chosenobih/hamrlinc:v0.3 -o hamrlinc_test -c /demo/PRJNA478205.csv -g Arabidopsis_thaliana.TAIR10.dna.toplevel.fa -i Arabidopsis_thaliana.TAIR10.57.gff3 -l 50 -s 135000000 -n 8 -k\n</code></pre></p>"},{"location":"Tutorial/#some-notes-on-software-behaviors-and-terminal-output","title":"Some Notes on Software Behaviors and Terminal Output","text":"<p>Please understand that this analysis is time-consuming in its nature, where the time limiting factors are the individual packages used themselves, like STAR, samtools, or GATK. While we have enabled parallel processing and multicore where possible, in general, the entire run should still take well over an hour, and over 10 hours for extreme cases. To save headaches, we have included several features:</p> <ul> <li>Every run will automatically create a new log file in your working directory</li> <li>If you ran into an error and the program exited, the next run will resume from the last saved checkpoint.</li> </ul> <p>Moreover, HAMRLINC can be unambiguously divided into 3 phases.</p>"},{"location":"Tutorial/#phase-1-fastq-preparation","title":"Phase 1: FASTQ Preparation","text":"<p>HAMRLINC will acquire or locate the fastq file. In the case of SRR accession code, we use SRA-toolkit's fasterq-dump function. Then, HAMRLINC trims each fastq with automatic adaptor detection with trim-galore, a wrapper around cutadapt. Finally, HAMRLINC performs fastqc for quality check. Files generated in this process are found in /datasets/trimmed and /datasets/fastqc. The trimmed fastq files will be used for alignment next.</p>"},{"location":"Tutorial/#phase-2-alignment-pre-processing-hamr-and-linc","title":"Phase 2: Alignment, Pre-processing, HAMR and LINC","text":"<p>HAMRLINC will use either STAR or TopHat2 to align each fastq to the provided reference genome. It will then pipe the output through a series of samtools, stringtie2, cufflink, and gatk commands to pre-process the bam file as required for HAMR or EVOLINC, before running either or both of them. During this phase, you will see [SAMPLEKEY] associated with every status message for each sample outputted by HAMRLINC. You will also see numerous lines outputted by each of the packages used. This phase tends to take the longest.</p>"},{"location":"Tutorial/#phase-3-post-processing-visualization","title":"Phase 3: Post-processing, Visualization","text":"<p>HAMRLINC will collect sequencing depth information with samtools coverage, call consensus across all replicates for each sample group (we take the union of pairwise intersection), overlap that consensus with the provided genome annotation file to associate different modifications with regions of an mRNA both structually (3', CDS, 5') and biologically (exon, non-coding). This information will then be summarized into mod_long.csv for the entire experiment (across different sample groups and sequencing methods). HAMRLINC will then generate some plots to help user visualize the spread, abundance, and types of each modification. During this, you might see many warning messages. Disregard them, unless an error is reported.</p>"},{"location":"Tutorial/#output-interpretation","title":"Output Interpretation","text":"<p>All outputs of HAMRLINC are organized in corresponding subdirectories of the output directory. When run with all three core processing enabled, HAMRLINC produces ten subdirectories in the output directory. Three subdirectories contain key intermediates like genome index files, trimmed fastq files and bed files, which can be used in various downstream processing of the user\u2019s choice. Three other subdirectories contain the raw output for each of the three core functionalities; one last subdirectory contains the visualizations and post-HAMR analysis results.</p> <p> </p> (a-g) Bar plots of the total abundance of HAMR predicted modifications by sample groups in CDS, exon, 5`UTR, gene, ncRNA, primary mRNA, and 3` UTR regions. (h) HAMR predicted modification abundance located in different RNA subtypes  <p> </p> (a-g) Bar plots of the abundance of HAMR predicted modification classes by sample groups in CDS, exon, 5`UTR, gene, ncRNA, primary mRNA, and 3` UTR regions. (h) Number of HAMR predicted modifications per gene region  <p> </p> (a) Distribution of modification types in gene regions by sample groups. (b) Distribution of modification types in gene regions  <p> </p> GO term heatmap and predicted enrichment landscape"},{"location":"commandline_arguments/","title":"Commandline Arguments","text":""},{"location":"commandline_arguments/#commandline-arguments-and-description","title":"Commandline Arguments and Description","text":"Command Description Required -o &lt;output directory&gt; name of the directory where you would like your hamrlinc run output files to be saved -c &lt;filenames for each fastq.csv&gt; a csv file that corresponds each SRA ID (or name of fastq file) to your desired nomenclature for each read. An example file is provided in the pipeline repo -g &lt;reference genome.fa&gt; a fasta file of the genome of the model organism -i &lt;reference genome annotation.gff3&gt; a gff3 file of the genome of the model organism, note we require gff3 instead of gtf -l &lt;read length&gt; an integer, the read length of this sequencing experiment, if non-unanimous use the shortest length -s &lt;genome size in bp&gt; an integer, the number of base pairs of the genome of this model organism Optional -n [number of threads] default=4 -d [raw fastq folder] a path to a folder containing raw fastq files if needed, in such case, -c csv should have each fastq file as key -a [use Tophat2 instead of STAR] default uses STAR -b [Tophat2 library choice: fr-unstranded, fr-firststrand, fr-secondstrand] default=fr-firststrand -f [filter] default=filter_SAM_number_hits.pl -k [activates modification analysis (left arm)] -p [activates lincRNA identification (inner right arm)] -u [activates regular featurecount (outer right arm)] -v [evolinc option: M or MO] default=M -Q [HAMR: minimum qualuty score] default=30 -C [HAMR: minimum coverage] default=10 -E [HAMR: sequencing error] default=0.01 -P [HAMR: maximum p-value] default=1 -F [HAMR: maximum FDR] default=0.05 -O [Panther organism taxon ID]  default=\"3702\" -A [Panther annotation dataset]  default=\"GO:0008150\" -Y [Panther test type: FISHER or BINOMIAL]  default=\"FISHER\" -R [Panther correction type: FDR, BONFERRONI, or NONE]  default=\"FDR\" -T &lt;/path/to/transposable_elements_file&gt; only required under evolinc MO option -G &lt;/path/to/CAGE_RNA_file&gt; only required under evolinc MO option -D &lt;/path/to/known_lincRNA_file&gt; only required under evolinc MO option -m [HAMR model] default=euk_trna_mods.Rdata -h [help message]"},{"location":"commandline_arguments/#input-reads","title":"Input reads","text":"<p>Read depth of input dataset is an important factor to consider if a user is interested in using HAMRLINC to annotate RNA modification. We recommend a read depth of at least 20M for paired-end reads and 40M for single reads, for diploid genomes. When having lower read depth and replicates, merge the datasets to get more depth of coverage.</p>"},{"location":"commandline_arguments/#reference-genome-and-annotation-files","title":"Reference genome and annotation files","text":"<p>We recommend that users download the reference genome and annotation files for their sample organism from ENSEMBL. This is because, we have observed that the annotation file from other sources for some of the organisms we tested didn't contain annotation for ncRNA transcripts. HAMRLINC relies on the information from the user supplied annotation file for the downstream classification of predicted modified transcripts into groups of RNA subytpes.</p>"},{"location":"commandline_arguments/#gene-ontology-go-term-heatmap-and-predicted-enrichment-landscape-of-modified-transcripts","title":"Gene ontology (GO) term heatmap and predicted enrichment landscape of modified transcripts","text":"<p>We use Panther's_API for generating the GO term heatmap of modified transcripts. Before activating the flag for this analysis, you need to first check panther's webiste for a list of panther's supported organisms to be sure that your sample organism is supported. If yes, kindly note the panther taxon ID for your sample organism. Next, check panther's supported annotation dataset website and note the GO function inference ID. For example, Molecular_function ID = \"GO:0003674\", Biological_process ID =     \"GO:0008150\", and Cellular_component =  \"GO:0005575\".</p>"},{"location":"commandline_arguments/#output-files","title":"Output files","text":"<p>In addtion to the result files and the files generated by the three core processing workflows integrated in HAMRLINC (HAMR, EVOLINC_I and Featurecount), we retain the last generated file(s) for each preprocessing step of the pipeline. These files can be used in different downstream processing based on the interest of the user.</p>"}]}